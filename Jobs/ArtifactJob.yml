# Artifact job helps perform different operations on artifacts without incurring additional
# overheads due to SDL analysis. A few examples are:
# 1. Download multiple pipeline artifacts and upload as a single artifactDrop
# 2. Download a single artifactDrop and upload into multiple pipelineArtifacts
parameters:

- name: job
  type: job
  default: {}

- name: sdl
  type: object

- name: pool
  type: object

- name: isOfficial
  type: boolean

- name: featureFlags
  type: object

- name: settings
  type: object

- name: allowedInputs
  type: object
  default:
  - pipelineArtifact
  - artifactsDrop

- name: predefinedOneESPTVariables
  type: object

- name: internalConfig
  type: object

jobs:
# Validation
- ${{ if parameters.job.steps }}:
  - "ArtifactJob cannot have 'steps'. Remove steps in this job.": error
- ${{ if not(parameters.job.templateContext.inputs) }}:
  - "ArtifactJob needs atleast one pipelineArtifact or artifactsDrop as input": error
- ${{ if not(parameters.job.templateContext.outputs) }}:
  - "ArtifactJob needs atleast one output": error
- ${{ each input in parameters.job.templateContext.inputs }}:
  - ${{ if not(containsValue(parameters.allowedInputs, input.input)) }}:
    - "Input '${{ input.input }}' is not allowed in ArtifactJob. Supported inputs: ${{ convertToJson(parameters.allowedInputs) }}": error

- ${{ each pair in parameters.job }}:
    ${{ if notIn(pair.key, 'arguments', 'steps', 'templateContext', 'variables') }}:
      ${{ pair.key }}: ${{ pair.value }}
  variables:
  - ${{ if parameters.job.variables }}:
    - ${{ each pair2 in parameters.job.variables }}:
      - ${{ if ne(pair2.key, '') }}:
        - name: ${{ pair2.key }}
          value: ${{ pair2.value }}
      - ${{ else }}:
        - ${{ insert }}: ${{ pair2 }}
  - ${{ parameters.predefinedOneESPTVariables }}
  steps:
  - checkout: none  # If this checkout is removed, update `skipSDLSourcesWhenCheckoutIsNoneForAllJobs` check in SDLSourceAnalysisJobInternal.yml
  # Process inputs
  - ${{ if parameters.job.templateContext.inputs }}:
    - ${{ each input in parameters.job.templateContext.inputs }}:
      - ${{ if and(or(input.pipeline, input.definition, input.project), or(eq(input.input, 'artifactsDrop'), eq(input.input, 'pipelineArtifact'))) }}:
        - "Using ArtifactJob to download artifacts from a different pipeline [${{ coalesce(input.pipeline, input.definition, input.project) }}] is not allowed. Please do not use 'pipeline', 'definition', or 'project' arguments in input section of ArtifactJob. See https://eng.ms/docs/cloud-ai-platform/devdiv/one-engineering-system-1es/1es-docs/1es-pipeline-templates/features/artifactjob for more details": error
    - template: ../Steps/Inputs.yml
      parameters:
        inputs: ${{ parameters.job.templateContext.inputs }}
        sdl: ${{ parameters.sdl }}
        runSbomValidation: false
        disableUserProvidedDestinationPath: false
        pool: ${{ parameters.pool }}

  # Process outputs
  - ${{ if parameters.job.templateContext.outputs }}:
    - template: ../Steps/Outputs.yml
      parameters:
        outputs: ${{ parameters.job.templateContext.outputs }}
        sdl: ${{ parameters.sdl }}
        target: host
        pool: ${{ parameters.pool }}
        isOfficial: ${{ parameters.isOfficial }}
        featureFlags: ${{ parameters.featureFlags }}
        settings: ${{ parameters.settings }}
        skipSDL: true
        internalConfig: ${{ parameters.internalConfig }}
